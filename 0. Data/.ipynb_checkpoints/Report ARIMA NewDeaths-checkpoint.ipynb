{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a4333bd",
   "metadata": {},
   "source": [
    "# ARIMA (autoregressive integrated moving average) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a784875b",
   "metadata": {},
   "source": [
    "## Import, handle missing values, create a clean dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b5eadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from math import floor, sqrt\n",
    "\n",
    "ic = pd.read_excel(\"D:\\DS\\Mine\\Corona\\I21-11.xlsx\", index_col=0, parse_dates=[0]) # Iran Corona for 2021-11-..\n",
    "ic['total_vaccinations_f'] = ic['total_vaccinations'].interpolate(method='linear')\n",
    "ic['stringency_index_f'] = ic['stringency_index'].fillna(method=\"ffill\")\n",
    "icf = ic.loc[ : , ['datei', 'total_cases', 'new_cases', 'new_cases_smoothed',\n",
    "                   'total_deaths', 'new_deaths', 'new_deaths_smoothed', 'total_vaccinations_f', 'stringency_index_f']]\n",
    "\n",
    "icf.loc[:, \"datei\"] = icf[\"datei\"].apply(lambda x: x - 43880)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "# pd.set_option('display.max_rows', 2000)\n",
    "icf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0867e34",
   "metadata": {},
   "source": [
    "## Checking stationarity of the data 'new_deaths'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc9751c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "icf.plot(y='new_deaths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11453fc4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "icn = icf.loc[:,'new_deaths']\n",
    "plot_acf(icn);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb2713b",
   "metadata": {},
   "outputs": [],
   "source": [
    "icd = icn.diff(periods=1)\n",
    "icd = icd[1:]\n",
    "icd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767ab029",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_acf(icd);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb43fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "icd.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb9405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "result = adfuller(icd)\n",
    "print('ADF Statistic: %f' % result[0])\n",
    "print('p-value: %f' % result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efc5099",
   "metadata": {},
   "source": [
    "**>> Using d = 1 (1 time differencing) the data becomes stationary (p-value < 0.05).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bda493",
   "metadata": {},
   "source": [
    "## Defining constants, spliting train and test for ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4fc1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = icn.shape[0]                #number of records\n",
    "train_len = floor(length * 0.90)     #90% of records are going to be used for training\n",
    "print('Out of', length, 'samples,', train_len, 'samples were devoted to training section and the rest (i.e.',\n",
    "      length - train_len, 'samples) to test section.')\n",
    "prl = 10                                    #prediction lendth: number of days to predict\n",
    "\n",
    "xd = icn.values\n",
    "xr = xd[:train_len]\n",
    "xs = xd[train_len:train_len+prl]\n",
    "xsp = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40b45e4",
   "metadata": {},
   "source": [
    "### Single set of parameters for an initial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af978cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running ARIMA using p=10, d=1 and q=1\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "print('On', icf.index[train_len].strftime('%Y-%m-%d'), 'a prediction of', prl, 'days is as follows:')\n",
    "arim = ARIMA(xr, order=(10, 1, 2))\n",
    "arim_fit = arim.fit()\n",
    "\n",
    "# print(arim_fit.aic)\n",
    "xsp = arim_fit.forecast(steps=prl)\n",
    "print('Using (p, d, q) = (3, 1, 1):')\n",
    "for i in range (prl):\n",
    "    print('Actual =', xs[i], '- predicted =', \"{:2.1f}\".format(xsp[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e494ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "arim_fit.params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ccb983",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "from math import sqrt, floor\n",
    "print('MAE:  Mean Absolute Error =           ', \"{:2.2f}\".format(mean_absolute_error(xs, xsp)))\n",
    "print('MAPE: Mean Absolute Percentage Error =', \"{:2.1%}\".format(mean_absolute_percentage_error(xs, xsp)))\n",
    "print('RMSE: Root Mean Squared Error =       ', \"{:2.2f}\".format(sqrt(mean_squared_error(xs, xsp))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8f8847",
   "metadata": {},
   "source": [
    "## Search to find the best parameters for ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0078927f",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87868bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = 30    #interval: is going to be used for predictions at every 'interval' records\n",
    "startp = 200     #start position: to start forcasting after this point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5883358b",
   "metadata": {},
   "source": [
    "### Parameters sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb809511",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools #To ease the process of combining parameters.\n",
    "\n",
    "#Parameter values:\n",
    "# pv = [1, 2, 3, 7, 10, 12, 14]#, 15, 16, 20]#, 30]#, 60]\n",
    "pv = range(1, 20)\n",
    "dv = range(0, 3)\n",
    "qv = range(0, 3)\n",
    "pdq = list(itertools.product(pv, dv, qv))\n",
    "print(len(pdq), 'set of parameters are going to be compared:')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f44fd8b",
   "metadata": {},
   "source": [
    "### Fitting models and RMSE comparison within the training section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bba273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import itertools\n",
    "import math\n",
    "from statistics import mean, stdev\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "lowest_rmse, best_cfg = float(\"inf\"), None\n",
    "cols = math.floor((train_len - startp - prl) / interval) #columns: is calculated to be used as the number of columns in this study\n",
    "rmse = np.zeros([len(pdq), cols]) #root mean square error \n",
    "print('Search to find best parameters using', len(pdq), 'parameters sets in', cols, 'points of dataset:')\n",
    "np.set_printoptions(precision=0)\n",
    "fit_model = [None]*len(pdq)\n",
    "\n",
    "for i in range(len(pdq)):\n",
    "    print('Parameters set', i, ': (p, d, q) =', pdq[i])\n",
    "    j = 0\n",
    "    while j < cols:\n",
    "        try:\n",
    "            model = ARIMA(xr[:startp+j*interval], order=pdq[i])\n",
    "            fit_model[i] = model.fit()\n",
    "            xs = xr[startp+(j*interval):startp+(j*interval)+prl]\n",
    "            xsp = fit_model[i].predict(start=startp+(j*interval), end=startp+(j*interval)+prl-1)\n",
    "            print('On', startp + j*interval, 'Actuals =', xs, 'Predictions =', xsp)\n",
    "            rmse[i][j] = sqrt(mean_squared_error(xs, xsp))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            j += 1\n",
    "            continue\n",
    "        j += 1\n",
    "       \n",
    "    if mean(rmse[i]) < lowest_rmse:\n",
    "        lowest_rmse, best_cfg = mean(rmse[i]), pdq[i]\n",
    "    print(\"  > RMSE:\",\"{:2.2f}\".format(mean(rmse[i])))\n",
    "      \n",
    "print('********************************* Best Score *********************************')\n",
    "print('Lowest RMSE', \"{:2.2f}\".format(lowest_rmse), 'was acheived using parameters set (p, d, q) =', best_cfg)\n",
    "# print(rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9190b5",
   "metadata": {},
   "source": [
    "### Prediction in test section using best set of parameters found above and calculations of errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c15a8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = xd[train_len : train_len + prl]\n",
    "print('On', icf.index[train_len].strftime('%Y-%m-%d'), 'a prediction of', prl, 'days is as follows:')\n",
    "try:\n",
    "    print('Using the best found set of parameters (p, d, q) =', best_cfg, ':')\n",
    "    xsp = ARIMA(xr, order=best_cfg).fit().predict(start=train_len, end=train_len+prl-1)\n",
    "    for i in range (prl):\n",
    "        print('Actual =', xs[i], '- predicted =', \"{:2.1f}\".format(xsp[i]))    \n",
    "\n",
    "    print('\\nMAE:  Mean Absolute Error =           ', \"{:2.2f}\".format(mean_absolute_error(xs, xsp)))\n",
    "    print('MAPE: Mean Absolute Percentage Error =', \"{:2.1%}\".format(mean_absolute_percentage_error(xs, xsp)))\n",
    "    print('RMSE: Root Mean Squared Error =       ', \"{:2.2f}\".format(sqrt(mean_squared_error(xs, xsp))))\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51a26d2",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6266c8e2",
   "metadata": {},
   "source": [
    "**>> In this notebook, we have established a technique to find the best set of parameters for ARIMA model in prediction of daily new deaths of corona. Briefly, the technique uses several points in the training section for the model to fit an ARIMA model and then use the fit model to predict some future values.**\n",
    "\n",
    "**Several attempts were made to implement the abovementioned searching and assessment techniques. The above technique can avoid overfitting by using tests that are outside of the training boundaries of each model.**\n",
    "\n",
    "**The model shows an acceptable performance within 10 days after the final available data. This model is based on the previous samples of the studied feature. Also as we are using the local data only, it cannot predict new peaks in cases/deaths using worldwide new variants outbreak. This limits the application of ARIMA to short term predictions (such as 1 or 2 weeks).**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
